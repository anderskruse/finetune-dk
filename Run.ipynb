{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f191f7f7-4ef7-47d7-a9cb-69c210179ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "/workspace\n",
      "Cloning into 'Qwen3-8B-Danish-Inst'...\n",
      "remote: Enumerating objects: 42, done.\u001b[K\n",
      "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
      "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
      "remote: Total 42 (delta 15), reused 32 (delta 8), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (42/42), 206.75 KiB | 2.27 MiB/s, done.\n",
      "Resolving deltas: 100% (15/15), done.\n",
      "/workspace/Qwen3-8B-Danish-Inst\n"
     ]
    }
   ],
   "source": [
    "# Start from root\n",
    "%cd /\n",
    "\n",
    "# Create and navigate to workspace\n",
    "!mkdir -p /workspace\n",
    "%cd /workspace\n",
    "\n",
    "# Remove old repo if exists\n",
    "!rm -rf Qwen3-8B-Danish-Inst\n",
    "\n",
    "# Clone fresh\n",
    "!git clone https://github.com/anderskruse/Qwen3-8B-Danish-Inst.git\n",
    "%cd Qwen3-8B-Danish-Inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43c8224d-e3a3-4228-bc4d-4152af4e2afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading uv 0.9.27 x86_64-unknown-linux-gnu\n",
      "no checksums to verify\n",
      "installing to /root/.local/bin\n",
      "  uv\n",
      "  uvx\n",
      "everything's installed!\n",
      "\u001b[31mWARN\u001b[m: The following commands are shadowed by other commands in your PATH: uv uvx\n",
      "Using CPython 3.12.3 interpreter at: \u001b[36m/usr/local/bin/python\u001b[39m\n",
      "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
      "Activate with: \u001b[32msource .venv/bin/activate\u001b[39m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m88 packages\u001b[0m \u001b[2min 624ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 572ms\u001b[0m\u001b[0m                                              \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m88 packages\u001b[0m \u001b[2min 360ms\u001b[0m\u001b[0m                              \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.12.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohappyeyeballs\u001b[0m\u001b[2m==2.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohttp\u001b[0m\u001b[2m==3.13.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiosignal\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.12.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==25.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbitsandbytes\u001b[0m\u001b[2m==0.49.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2026.1.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcuda-bindings\u001b[0m\u001b[2m==12.9.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcuda-pathfinder\u001b[0m\u001b[2m==1.3.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcut-cross-entropy\u001b[0m\u001b[2m==25.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdill\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdocstring-parser\u001b[0m\u001b[2m==0.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfrozenlist\u001b[0m\u001b[2m==1.8.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhf-transfer\u001b[0m\u001b[2m==0.1.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhf-xet\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.36.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmsgspec\u001b[0m\u001b[2m==0.20.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmultidict\u001b[0m\u001b[2m==6.7.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmultiprocess\u001b[0m\u001b[2m==0.70.16\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.8.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.10.2.21\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.3.83\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.13.1.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.9.90\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.3.90\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.8.93\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.27.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvshmem-cu12\u001b[0m\u001b[2m==3.4.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==26.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpeft\u001b[0m\u001b[2m==0.18.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==12.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpropcache\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.33.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==7.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==23.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mqwen3-danish-finetune\u001b[0m\u001b[2m==0.1.0 (from file:///workspace/Qwen3-8B-Danish-Inst)\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2026.1.15\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.8.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msentence-transformers\u001b[0m\u001b[2m==5.2.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msentencepiece\u001b[0m\u001b[2m==0.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==80.10.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.22.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchao\u001b[0m\u001b[2m==0.15.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.25.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtrl\u001b[0m\u001b[2m==0.24.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtypeguard\u001b[0m\u001b[2m==4.4.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.15.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyro\u001b[0m\u001b[2m==1.0.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1munsloth\u001b[0m\u001b[2m==2026.1.4 (from git+https://github.com/unslothai/unsloth.git@e51d3ea2e498fc893770d92ca6727bd113918480)\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1munsloth-zoo\u001b[0m\u001b[2m==2026.1.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwheel\u001b[0m\u001b[2m==0.46.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mxxhash\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1myarl\u001b[0m\u001b[2m==1.22.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "!~/.local/bin/uv venv .venv --clear\n",
    "!~/.local/bin/uv pip install -e . --python .venv/bin/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68250876-eeea-4f24-9c1b-e013c0ef8fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"[]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b095c5c4-1619-4d04-a87c-7e1d42ea045d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'user',\n",
       " 'id': '68dc10a23a2b55c87699aa21',\n",
       " 'name': 'AndersMK',\n",
       " 'fullname': 'K',\n",
       " 'email': 'amkruse@gmail.com',\n",
       " 'emailVerified': True,\n",
       " 'canPay': False,\n",
       " 'billingMode': 'prepaid',\n",
       " 'periodEnd': 1769904000,\n",
       " 'isPro': False,\n",
       " 'avatarUrl': '/avatars/58a26212dbf6f460725db4cc6ac90186.svg',\n",
       " 'orgs': [],\n",
       " 'auth': {'type': 'access_token',\n",
       "  'accessToken': {'displayName': 'hf_code2',\n",
       "   'role': 'write',\n",
       "   'createdAt': '2026-01-27T20:02:26.110Z'}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import whoami\n",
    "whoami()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cb6fc2b-d199-4fb8-90b5-76b7927ea2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.10.0+cu128\n"
     ]
    }
   ],
   "source": [
    "!.venv/bin/python -c \"import torch; print(f'PyTorch: {torch.__version__}')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a90e0a3b-b368-4663-a4cc-23ea0e4358c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "Loading model...\n",
      "==((====))==  Unsloth 2026.1.4: Fast Qwen3 patching. Transformers: 4.57.6.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 5090. Num GPUs = 1. Max memory: 31.357 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 12.0. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.53s/it]\n",
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2026.1.4 patched 36 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n",
      "Loading dataset...\n",
      "Formatting 21580 examples...\n",
      "Unsloth: Tokenizing [\"text\"] (num_proc=388): 100%|‚ñâ| 21537/21580 [00:18<00:00, 1\n",
      "Starting training...\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 21,580 | Num Epochs = 1 | Total steps = 1,349\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 43,646,976 of 8,234,382,336 (0.53% trained)\n",
      "{'loss': 2.009, 'grad_norm': 0.3094193935394287, 'learning_rate': 4.9e-05, 'epoch': 0.04}\n",
      "{'loss': 1.4424, 'grad_norm': 0.259828120470047, 'learning_rate': 9.900000000000001e-05, 'epoch': 0.07}\n",
      "{'loss': 1.3494, 'grad_norm': 0.27900561690330505, 'learning_rate': 9.607686148919136e-05, 'epoch': 0.11}\n",
      "{'loss': 1.3087, 'grad_norm': 0.2952956557273865, 'learning_rate': 9.207365892714172e-05, 'epoch': 0.15}\n",
      "{'loss': 1.2977, 'grad_norm': 0.303151398897171, 'learning_rate': 8.807045636509208e-05, 'epoch': 0.19}\n",
      "{'loss': 1.287, 'grad_norm': 0.3483901023864746, 'learning_rate': 8.406725380304243e-05, 'epoch': 0.22}\n",
      "{'loss': 1.2292, 'grad_norm': 0.41045451164245605, 'learning_rate': 8.00640512409928e-05, 'epoch': 0.26}\n",
      "{'loss': 1.2124, 'grad_norm': 0.4110730290412903, 'learning_rate': 7.606084867894315e-05, 'epoch': 0.3}\n",
      "{'loss': 1.2132, 'grad_norm': 0.4025343358516693, 'learning_rate': 7.205764611689351e-05, 'epoch': 0.33}\n",
      "{'loss': 1.2316, 'grad_norm': 0.4090142548084259, 'learning_rate': 6.805444355484388e-05, 'epoch': 0.37}\n",
      "{'loss': 1.2041, 'grad_norm': 0.40404507517814636, 'learning_rate': 6.405124099279424e-05, 'epoch': 0.41}\n",
      "{'loss': 1.1739, 'grad_norm': 0.39970406889915466, 'learning_rate': 6.00480384307446e-05, 'epoch': 0.44}\n",
      "{'loss': 1.2064, 'grad_norm': 0.4090234339237213, 'learning_rate': 5.604483586869496e-05, 'epoch': 0.48}\n",
      "{'loss': 1.1748, 'grad_norm': 0.4446602463722229, 'learning_rate': 5.2041633306645324e-05, 'epoch': 0.52}\n",
      "{'loss': 1.179, 'grad_norm': 0.3974789083003998, 'learning_rate': 4.803843074459568e-05, 'epoch': 0.56}\n",
      "{'loss': 1.1521, 'grad_norm': 0.4806358516216278, 'learning_rate': 4.403522818254604e-05, 'epoch': 0.59}\n",
      "{'loss': 1.1864, 'grad_norm': 0.5657838582992554, 'learning_rate': 4.00320256204964e-05, 'epoch': 0.63}\n",
      "{'loss': 1.1813, 'grad_norm': 0.41674235463142395, 'learning_rate': 3.602882305844676e-05, 'epoch': 0.67}\n",
      "{'loss': 1.1367, 'grad_norm': 0.5074273347854614, 'learning_rate': 3.202562049639712e-05, 'epoch': 0.7}\n",
      "{'loss': 1.167, 'grad_norm': 0.4521830379962921, 'learning_rate': 2.802241793434748e-05, 'epoch': 0.74}\n",
      "{'loss': 1.1657, 'grad_norm': 0.4085635840892792, 'learning_rate': 2.401921537229784e-05, 'epoch': 0.78}\n",
      "{'loss': 1.1362, 'grad_norm': 0.4482632279396057, 'learning_rate': 2.00160128102482e-05, 'epoch': 0.82}\n",
      "{'loss': 1.1781, 'grad_norm': 0.4515876770019531, 'learning_rate': 1.601281024819856e-05, 'epoch': 0.85}\n",
      "{'loss': 1.1406, 'grad_norm': 0.4735167324542999, 'learning_rate': 1.200960768614892e-05, 'epoch': 0.89}\n",
      "{'loss': 1.1415, 'grad_norm': 0.4728069007396698, 'learning_rate': 8.00640512409928e-06, 'epoch': 0.93}\n",
      "{'loss': 1.1638, 'grad_norm': 0.409394770860672, 'learning_rate': 4.00320256204964e-06, 'epoch': 0.96}\n",
      "{'train_runtime': 3458.8568, 'train_samples_per_second': 6.239, 'train_steps_per_second': 0.39, 'train_loss': 1.2380702398369452, 'epoch': 1.0}\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1349/1349 [57:38<00:00,  2.56s/it]\n",
      "Saving model...\n",
      "Saving merged model...\n",
      "config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 754/754 [00:00<00:00, 4.00MB/s]\n",
      "Found HuggingFace hub cache directory: /workspace/.cache/huggingface/hub\n",
      "model.safetensors.index.json: 32.9kB [00:00, 54.7MB/s]\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: model-00001-of-00004.safetensors not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: tokenizer.model not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n",
      "Unsloth: Preparing safetensor model files:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "model-00001-of-00004.safetensors:   0%|             | 0.00/4.90G [00:00<?, ?B/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|    | 3.23M/4.90G [00:00<24:10, 3.38MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|    | 17.9M/4.90G [00:01<03:50, 21.2MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|    | 31.2M/4.90G [00:01<02:09, 37.6MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|    | 40.5M/4.90G [00:01<01:50, 44.2MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|    | 52.9M/4.90G [00:01<01:48, 44.7MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|‚ñè     | 134M/4.90G [00:01<00:33, 143MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|‚ñè     | 203M/4.90G [00:01<00:22, 213MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|‚ñé     | 239M/4.90G [00:02<00:20, 228MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|‚ñé     | 289M/4.90G [00:02<00:21, 220MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|‚ñç     | 404M/4.90G [00:02<00:11, 379MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|‚ñå     | 469M/4.90G [00:02<00:10, 412MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|‚ñã     | 524M/4.90G [00:02<00:10, 425MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|‚ñâ     | 718M/4.90G [00:02<00:06, 688MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|‚ñà     | 849M/4.90G [00:03<00:06, 639MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|‚ñà‚ñè   | 1.13G/4.90G [00:03<00:03, 980MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|‚ñà‚ñé   | 1.28G/4.90G [00:03<00:03, 921MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|‚ñà‚ñè  | 1.48G/4.90G [00:03<00:03, 1.03GB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  37%|‚ñà‚ñç  | 1.82G/4.90G [00:03<00:02, 1.49GB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  43%|‚ñà‚ñã  | 2.13G/4.90G [00:03<00:01, 1.80GB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|‚ñà‚ñà  | 2.49G/4.90G [00:03<00:01, 2.20GB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|‚ñà‚ñà‚ñè | 2.75G/4.90G [00:04<00:01, 1.92GB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  66%|‚ñà‚ñà‚ñã | 3.24G/4.90G [00:04<00:00, 2.55GB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  73%|‚ñà‚ñà‚ñâ | 3.58G/4.90G [00:04<00:00, 2.69GB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|‚ñà‚ñà‚ñà‚ñé| 4.12G/4.90G [00:04<00:00, 3.22GB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  92%|‚ñà‚ñà‚ñà‚ñã| 4.50G/4.90G [00:04<00:00, 3.06GB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà| 4.90G/4.90G [00:04<00:00, 1.05GB/s]\u001b[A\n",
      "Unsloth: Preparing safetensor model files:  25%|‚ñå | 1/4 [00:04<00:14,  4.87s/it]\n",
      "model-00002-of-00004.safetensors:   0%|             | 0.00/4.92G [00:00<?, ?B/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   0%| | 39.6k/4.92G [00:00<14:19:35, 95.3kB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   0%|     | 964k/4.92G [00:00<34:24, 2.38MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   0%|    | 9.39M/4.92G [00:00<03:39, 22.3MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   1%|    | 37.1M/4.92G [00:00<00:59, 81.4MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   1%|     | 63.2M/4.92G [00:00<00:46, 105MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   2%|     | 85.2M/4.92G [00:01<00:45, 107MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   2%|      | 102M/4.92G [00:01<00:41, 116MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   4%|‚ñè     | 187M/4.92G [00:01<00:17, 278MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   5%|‚ñé     | 229M/4.92G [00:01<00:20, 227MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   7%|‚ñç     | 338M/4.92G [00:01<00:12, 360MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   8%|‚ñå     | 414M/4.92G [00:01<00:11, 382MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  10%|‚ñå     | 486M/4.92G [00:02<00:11, 401MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  12%|‚ñã     | 569M/4.92G [00:02<00:09, 464MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  14%|‚ñä     | 683M/4.92G [00:02<00:07, 571MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  19%|‚ñà     | 912M/4.92G [00:02<00:04, 930MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  21%|‚ñä   | 1.05G/4.92G [00:02<00:03, 1.02GB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  25%|‚ñà   | 1.24G/4.92G [00:02<00:02, 1.24GB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  28%|‚ñà‚ñç   | 1.38G/4.92G [00:02<00:03, 953MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  32%|‚ñà‚ñé  | 1.56G/4.92G [00:03<00:03, 1.05GB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  35%|‚ñà‚ñç  | 1.72G/4.92G [00:03<00:02, 1.13GB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  39%|‚ñà‚ñå  | 1.90G/4.92G [00:03<00:02, 1.13GB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  45%|‚ñà‚ñä  | 2.23G/4.92G [00:03<00:01, 1.39GB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  50%|‚ñà‚ñâ  | 2.45G/4.92G [00:03<00:01, 1.59GB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  58%|‚ñà‚ñà‚ñé | 2.86G/4.92G [00:03<00:00, 2.15GB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  65%|‚ñà‚ñà‚ñå | 3.18G/4.92G [00:03<00:00, 2.15GB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  70%|‚ñà‚ñà‚ñä | 3.45G/4.92G [00:04<00:00, 1.93GB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  88%|‚ñà‚ñà‚ñà‚ñå| 4.33G/4.92G [00:04<00:00, 3.42GB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà| 4.92G/4.92G [00:04<00:00, 1.10GB/s]\u001b[A\n",
      "Unsloth: Preparing safetensor model files:  50%|‚ñà | 2/4 [00:09<00:09,  4.73s/it]\n",
      "model-00003-of-00004.safetensors:   0%|             | 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   0%|    | 3.88M/4.98G [00:00<20:05, 4.13MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   0%|    | 8.36M/4.98G [00:01<08:59, 9.22MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   0%|    | 20.8M/4.98G [00:01<03:09, 26.2MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   1%|    | 41.3M/4.98G [00:01<01:31, 54.1MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   2%|     | 90.8M/4.98G [00:01<00:36, 133MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   3%|‚ñè     | 135M/4.98G [00:01<00:25, 191MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   5%|‚ñé     | 272M/4.98G [00:01<00:11, 420MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   7%|‚ñç     | 371M/4.98G [00:01<00:08, 526MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  10%|‚ñå     | 502M/4.98G [00:01<00:06, 689MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  12%|‚ñã     | 607M/4.98G [00:02<00:07, 561MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  15%|‚ñâ     | 731M/4.98G [00:02<00:07, 589MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  17%|‚ñâ     | 823M/4.98G [00:02<00:08, 514MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  18%|‚ñà     | 902M/4.98G [00:02<00:07, 556MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  20%|‚ñà‚ñè    | 990M/4.98G [00:02<00:08, 474MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  23%|‚ñà‚ñè   | 1.15G/4.98G [00:03<00:05, 678MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  25%|‚ñà‚ñé   | 1.27G/4.98G [00:03<00:05, 720MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  30%|‚ñà‚ñè  | 1.52G/4.98G [00:03<00:03, 1.05GB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  34%|‚ñà‚ñã   | 1.69G/4.98G [00:03<00:03, 946MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  38%|‚ñà‚ñâ   | 1.89G/4.98G [00:03<00:03, 980MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  47%|‚ñà‚ñä  | 2.33G/4.98G [00:03<00:01, 1.61GB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  51%|‚ñà‚ñà  | 2.54G/4.98G [00:03<00:01, 1.67GB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  59%|‚ñà‚ñà‚ñé | 2.94G/4.98G [00:04<00:00, 2.09GB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  65%|‚ñà‚ñà‚ñå | 3.25G/4.98G [00:04<00:00, 2.30GB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  73%|‚ñà‚ñà‚ñâ | 3.64G/4.98G [00:04<00:00, 2.40GB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  79%|‚ñà‚ñà‚ñà‚ñè| 3.95G/4.98G [00:04<00:00, 2.49GB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà| 4.98G/4.98G [00:04<00:00, 1.07GB/s]\u001b[A\n",
      "Unsloth: Preparing safetensor model files:  75%|‚ñà‚ñå| 3/4 [00:14<00:04,  4.78s/it]\n",
      "model-00004-of-00004.safetensors:   0%|             | 0.00/1.58G [00:00<?, ?B/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   0%|     | 644k/1.58G [00:00<20:06, 1.31MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   0%|    | 7.33M/1.58G [00:00<02:01, 13.0MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   3%|‚ñè   | 49.6M/1.58G [00:00<00:19, 78.7MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   5%|‚ñè   | 81.2M/1.58G [00:01<00:16, 92.7MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  11%|‚ñã     | 175M/1.58G [00:01<00:06, 219MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  28%|‚ñà‚ñã    | 443M/1.58G [00:01<00:01, 633MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  45%|‚ñà‚ñà‚ñé  | 712M/1.58G [00:01<00:00, 1.02GB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  62%|‚ñà‚ñà‚ñà  | 977M/1.58G [00:01<00:00, 1.35GB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 1.58G/1.58G [00:01<00:00, 847MB/s]\u001b[A\n",
      "Unsloth: Preparing safetensor model files: 100%|‚ñà‚ñà| 4/4 [00:16<00:00,  4.10s/it]\n",
      "Note: tokenizer.model not found (this is OK for non-SentencePiece models)\n",
      "Unsloth: Merging weights into 16bit: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:27<00:00,  6.93s/it]\n",
      "Unsloth: Merge process complete. Saved to `/workspace/Qwen3-8B-Danish-Inst/outputs/merged_model`\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!.venv/bin/python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc892d6e-3dfe-4b7e-b02f-a536a5be724b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "Loading: ./outputs/merged_model\n",
      "==((====))==  Unsloth 2026.1.4: Fast Qwen3 patching. Transformers: 4.57.6.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 5090. Num GPUs = 1. Max memory: 31.357 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 12.0. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:09<00:00,  2.35s/it]\n",
      "\n",
      "============================================================\n",
      "\n",
      "Q: Hvad er koldsk√•l?\n",
      "A: system\n",
      "Du er en hj√¶lpsom assistent.\n",
      "user\n",
      "Hvad er koldsk√•l?\n",
      "assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "En koldsk√•l er en type koldt m√•ltid, der best√•r af en blanding af frugt, √¶ble-, oranjepulver og andre smagsfulde ingredienser, som bruges til at lave kage eller krem. Det er en god tilf√∏jelse til en sund kost og kan serveres som dessert eller snack.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Q: Forklar hygge p√• dansk.\n",
      "A: system\n",
      "Du er en hj√¶lpsom assistent.\n",
      "user\n",
      "Forklar hygge p√• dansk.\n",
      "assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hygge p√• dansk er et begreb, der handler om en f√∏lelse af forn√∏jelse, velbehag og tilfredshed, der opn√•s, n√•r man er sammen med venner eller familie. Det er som at have en hyggefest, hvor du stikker din n√¶se i en varm kage og griner, mens pigerne sidder og snakker om, hvad der skete i skolen.\n",
      "\n",
      "Hygge betyder, at du f√•r en f√∏lelse af, at du har det godt, n√•r du er sammen med andre, og at du er glad for at v√¶re der. Det kan ske, n√•r du sidder p√• en bus og taler med en ven, eller n√•r der er en familiefest, hvor alle griner og danser sammen. Hygge er som en smuk solglimt, der skaber en f√∏lelse af, at du har det godt og er glad for det.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Q: Hvem var Grundtvig?\n",
      "A: system\n",
      "Du er en hj√¶lpsom assistent.\n",
      "user\n",
      "Hvem var Grundtvig?\n",
      "assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Grundtvig var en fiktiv skolekarakter, der blev skabt af en gruppe elever for at have en bedre tid under fritiden. De tog Grundtvig til at v√¶re et barn, der kunne v√¶re god til at lege og lide at spille med andre b√∏rn. De kunne bruge Grundtvig til at introducere nye spil og aktiviteter til klassen.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Q: Skriv en kort opskrift p√• sm√∏rrebr√∏d.\n",
      "A: system\n",
      "Du er en hj√¶lpsom assistent.\n",
      "user\n",
      "Skriv en kort opskrift p√• sm√∏rrebr√∏d.\n",
      "assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Sm√∏rrebr√∏d er et popul√¶rt og let at lave madtilbeh√∏r, der best√•r af to tynde, smalle br√∏dst√¶nger, ofte af rugbrot, og en kryddet sm√∏r eller kugler af sm√∏r. Denne enkle form for sm√∏rrebr√∏d er en del af den nordiske madkultur og kan serveres som et snack, en anden m√•ltid eller en del af en m√•ltidseventyr.\n",
      "\n",
      "Her er en kort opskrift:\n",
      "\n",
      "1. Fjern toppen af rugbrotet (den del, der er n√¶rmest dekken). Klarg√∏r rugbrotet, s√• det er klar til at sm√∏re.\n",
      "2. Sm√∏r p√• begge sides af rugbrotet. Brug en sm√∏rskevle, et sm√∏rskar eller bare dine h√¶nder for at sm√∏re.\n",
      "3. Server sm√∏rrebr√∏det smurt p√• begge sides.\n",
      "\n",
      "Sm√∏rrebr√∏d kan smages p√• forskellige m√•der, afh√¶ngigt af dine pr√¶ferencer eller de tilg√¶ngelige ingredienser. En klassisk\n",
      "------------------------------------------------------------\n",
      "\n",
      "Q: Hvad er forskellen mellem r√∏dgr√∏d og risalamande?\n",
      "A: system\n",
      "Du er en hj√¶lpsom assistent.\n",
      "user\n",
      "Hvad er forskellen mellem r√∏dgr√∏d og risalamande?\n",
      "assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "R√∏dgr√∏d og risalamande er tv√¶rg√•ende popul√¶re dessertmadser af forskellige r√∏dder og traditioner. Selvom begge kan opfattes som slanke dessertmad til en fest eller en fest, har de forskellige historiske baggrunde, ingredienser og fremstillingsmetoder.\n",
      "\n",
      "Trin 1: Forst√• forskellene i historien.\n",
      "R√∏dgr√∏d har sin r√∏dder i det kinesisk-mandjiske imperium, hvor den oprindeligt var en tilberedning til √•bne tidsperioder som for√•ret og sommeren. I mods√¶tning hertil er risalamade en traditionel √∏stasiatisk dessert, som opstod i Japan og senere spredte sig til andre dele af Asien.\n",
      "\n",
      "Trin 2: Analyser forskellene i ingredienser.\n",
      "R√∏dgr√∏d best√•r hovedsagelig af r√∏dt gr√∏nt frugt- og t√∏rfrugtsblanding, som typisk best√•r af r√∏dfugle, r√∏dle, kogte √¶bler og sitronskor\n",
      "------------------------------------------------------------\n",
      "\n",
      "Q: Forklar kvantemekanik p√• simpelt dansk.\n",
      "A: system\n",
      "Du er en hj√¶lpsom assistent.\n",
      "user\n",
      "Forklar kvantemekanik p√• simpelt dansk.\n",
      "assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Kvantemekanik er en type matematik, der hj√¶lper os med at forst√•, hvordan sm√• ting som atomer og fotoner fungerer. Det er som at studere en st√¶rk magnet, som kan holde sm√• s√∏mne i luften. Det er lidt kompliceret, men det er som at se, hvordan magneten kan holde s√∏mne i luften, men de har ogs√• lidt magisk energi, der f√•r dem til at bev√¶ge sig p√• en anden m√•de.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!.venv/bin/python evaluate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7931997-44c0-477e-87a2-8603587d704e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
